{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Name: **Analytics Acrobats**\n",
    "\n",
    "### Submission: **1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed to ensure reproducibility\n",
    "\n",
    "seed = 2024\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "\n",
    "diet = pd.read_csv('diet.csv')\n",
    "requests = pd.read_csv('requests.csv')\n",
    "reviews = pd.read_csv('reviews.csv')\n",
    "recipes = pd.read_csv('recipes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diet.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overview of the diet dataset\n",
    "\n",
    "print(diet.head())\n",
    "print(diet.info())\n",
    "print(diet.isnull().sum())\n",
    "\n",
    "# --> One missing value in \"Diet\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptives for diet dataset\n",
    "\n",
    "print(diet.describe())\n",
    "\n",
    "# boxplot for age\n",
    "print(sns.boxplot(diet));\n",
    "\n",
    "# barplot for diet\n",
    "\n",
    "print(sns.countplot(x='Diet', data=diet));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rows with missing values in diet dataset\n",
    "\n",
    "print(diet[diet.isnull().any(axis=1)])\n",
    "\n",
    "# what does this user do in the other tables? -> user has no requests or reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is only one row, drop rows with missing values in diet dataset\n",
    "\n",
    "diet = diet.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column \"Diet\" of type category\n",
    "\n",
    "diet['Diet'] = diet['Diet'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert categorical to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dummy variable encoding for \"Diet\" column\n",
    "\n",
    "diet = pd.get_dummies(diet, columns=['Diet'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recipes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overview of the recipes dataset\n",
    "\n",
    "print(recipes.head())\n",
    "print(recipes.info())\n",
    "print(recipes.isnull().sum())\n",
    "\n",
    "# --> Missing values in columns \"RecipeServings\" and \"RecipeYield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptives for recipes dataset\n",
    "\n",
    "print(recipes.describe())\n",
    "\n",
    "# countplot for RecipeCategory\n",
    "print(recipes['RecipeCategory'].value_counts())\n",
    "\n",
    "print(sns.countplot(x='RecipeCategory', data=recipes));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column for now\n",
    "\n",
    "recipes = recipes.drop(columns=['Name'])\n",
    "\n",
    "# TO DO: Do we need the column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle CookTime and PrepTime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing values in both columns\n",
    "\n",
    "# TO DO: Handle outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle RecipeCategory column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy encode RecipeCategory column\n",
    "\n",
    "recipes = pd.get_dummies(recipes, columns=['RecipeCategory'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle RecipeIngredientQuantities and RecipeIngredientParts column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just drop the columns for now\n",
    "\n",
    "recipes = recipes.drop(['RecipeIngredientQuantities', 'RecipeIngredientParts'], axis=1)\n",
    "\n",
    "# TO DO: Handle them better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle all nutrition fact columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Handle potential outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle RecipeServings and RecipeYield column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just drop the columns for now\n",
    "\n",
    "recipes = recipes.drop(['RecipeServings', 'RecipeYield'], axis=1)\n",
    "\n",
    "# TO DO: Handle missing values, outliers and weird values in RecipeYield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviews.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overview of the reviews dataset\n",
    "\n",
    "print(reviews.head())\n",
    "print(reviews.info())\n",
    "print(reviews.isnull().sum())\n",
    "\n",
    "# --> Missing values in columns \"Rating\", \"Like\" and \"TestSetId\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptives for reviews dataset\n",
    "\n",
    "print(reviews.describe())\n",
    "\n",
    "print(reviews['Rating'].value_counts());\n",
    "\n",
    "print(reviews['Like'].value_counts()); # --> make true = 1 and false = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split datasets in prediction and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into submission that needs to be predicted and the rest we can use\n",
    "\n",
    "# 1. Get the rows without missing values in \"TestSetId\" column \n",
    "# and missing values in \"Like\" column\n",
    "\n",
    "reviews_to_predict = reviews[reviews['TestSetId'].notnull() & reviews['Like'].isnull()]\n",
    "\n",
    "# 2. Get the rows with missing values in \"TestSetId\" column\n",
    "\n",
    "reviews_to_use = reviews[reviews['TestSetId'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_to_use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove unneccesary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column \"Rating\" since it has either no value or only 2.0 -> no information\n",
    "# Remove column \"TestSetId\" since only NA values\n",
    "\n",
    "reviews_to_use = reviews_to_use.drop(['Rating', 'TestSetId'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change type of column Like to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make column \"Like\" binary, true = 1 and false = 0\n",
    "\n",
    "reviews_to_use['Like'] = reviews_to_use['Like'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_to_use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requests.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overview of the request dataset\n",
    "\n",
    "print(requests.head())\n",
    "print(requests.info())\n",
    "print(requests.isnull().sum())\n",
    "\n",
    "# --> No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change types of columns with flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests['HighCalories'] = requests['HighCalories'].astype('int')\n",
    "\n",
    "# In \"HighProtein\", encode yes = 1 and indifferent = 0\n",
    "requests['HighProtein'] = requests['HighProtein'].map({'Yes': 1, 'Indifferent': 0})\n",
    "\n",
    "# In \"LowSugar\", encode no = 1 and indifferent = 0\n",
    "requests['LowSugar'] = requests['LowSugar'].map({'0': 1, 'Indifferent': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Round time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round time column to integer values and cast to int\n",
    "\n",
    "requests['Time'] = requests['Time'].round().astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the differences in columns \"AuthorId / RecipeId\" in reviews and requests dataset\n",
    "\n",
    "#print(set(requests['AuthorId']) - set(reviews_to_use['AuthorId']))\n",
    "#print(set(requests['RecipeId']) - set(reviews_to_use['RecipeId']))\n",
    "\n",
    "# -> request has the exact same keys as reviews \n",
    "# -> merge on reviews_to_use where matches occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join requests and reviews_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join requests and reviews_to_use on AuthorId and RecipeId\n",
    "\n",
    "requests_reviews = pd.merge(requests, reviews_to_use, on=['AuthorId', 'RecipeId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join requests_reviews and diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join requests_reviews and diet on AuthorId\n",
    "\n",
    "requests_reviews_diet = pd.merge(requests_reviews, diet, on='AuthorId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join requests_reviews_diet and recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join requests_reviews_diet and recipes on RecipeId\n",
    "\n",
    "requests_reviews_diet_recipes = pd.merge(requests_reviews_diet, recipes, on='RecipeId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_reviews_diet_recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Split data into train and test set\n",
    "\n",
    "#X = requests_reviews_diet_recipes.drop(['AuthorId', 'RecipeId', 'HighCalories', 'HighProtein', 'LowSugar', 'Like'], axis=1)\n",
    "X = requests_reviews_diet_recipes.drop(['AuthorId', 'RecipeId', 'Like'], axis=1)\n",
    "y = requests_reviews_diet_recipes['Like']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "\n",
    "# Fit logistic regression model\n",
    "\n",
    "logmodel = LogisticRegression(max_iter=1000)\n",
    "logmodel.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions = logmodel.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "\n",
    "print(balanced_accuracy_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
