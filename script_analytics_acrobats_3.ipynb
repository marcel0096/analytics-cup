{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the Packages\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set the display format for floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Seed (pandas, statsmodels, matplotlib and y_data_profiling rely on numpy's random generator, and thus, we need to set the seed in numpy)\n",
    "seed = 2024\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the display format for floats\n",
    "pd.set_option('display.float_format', lambda x: '{:.2f}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data \n",
    "diet_df = pd.read_csv(\"diet.csv\")\n",
    "recipes_df = pd.read_csv(\"recipes.csv\")\n",
    "requests_df = pd.read_csv(\"requests.csv\")\n",
    "reviews_df = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Diet Shape: \", diet_df.shape)\n",
    "print(\"Recipes Shape: \", recipes_df.shape)\n",
    "print(\"Requests Shape: \", requests_df.shape)\n",
    "print(\"Reviews Shape: \", reviews_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Diet ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Diet\n",
    "diet_cleaned = diet_df \n",
    "\n",
    "# Replace the missing values with the most common diet\n",
    "diet_cleaned.loc[diet_df[\"AuthorId\"] == \"646062A\", \"Diet\"] = \"Vegetarian\"\n",
    "\n",
    "# Dummy Encode the diet column\n",
    "diet_cleaned = pd.get_dummies(diet_cleaned, columns=[\"Diet\"], prefix=[\"Diet\"], drop_first=True)\n",
    "\n",
    "diet_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_df.head()\n",
    "recipes_cleaned = recipes_df.copy()\n",
    "\n",
    "recipes_df[\"Calories\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "vegetables = 'carrot|potato|tomato|onion|garlic|broccoli|spinach|cucumber|lettuce|celery|cabbage|cauliflower|corn|pepper|peas|beans|asparagus|eggplant|zucchini|squash|pumpkin|radish|beet|turnip|sprouts|vegetable|vegetables|kale|bell pepper|sweet potato|cherry tomato|artichoke|bok choy|brussels sprouts|butternut squash|leek|okra|snow peas|snap peas|green beans|fennel|watercress|arugula|chard|collard greens|endive|escarole|kohlrabi|mustard greens|pattypan squash|romanesco broccoli|rutabaga|sugar snap peas|swiss chard|tatsoi|water chestnut|yam|daikon|lotus root|bamboo shoots|jicama|plantain|radicchio|turnip greens|water spinach|bitter melon|chayote|chicory|dandelion greens|edamame|lotus root|nopales|portobello mushroom|shiitake mushroom|maitake mushroom|enoki mushroom|oyster mushroom|mushroom|zucchini blossom|artichoke|sunchoke|beets|cardoon|salsify|kale|endive|acorn squash|alfalfa sprout|amaranth|anise|arracacha|arrowroot|aubergine|avocado|azuki bean|banana squash|barbarea verna|basil|bean sprout|beet greens|belgian endive|bell pepper|black bean|black-eyed pea|borage|broad bean|broccoflower|broccolini|brussels sprout|butter lettuce|butternut lettuce|cactus|calabash|camas root|canna|cape gooseberry|caper|cardinal bean|cassava|catsear|cauliflower|cayenne pepper|celeriac|celtuce|chayote|cherry pepper|chickpea|chicory|chili pepper|chinese artichoke|chinese broccoli|chinese cabbage|chinese mallow|chive|cilantro|collard|common bean|courgette|courgette flower|cowpea|cress|crookneck squash|cucumber|daikon|delicata squash|dill|drumstick|earthnut pea|elephant garlic|endive|epazote|fava bean|fennel|fenugreek|fluted pumpkin|french bean|frisee|garbanzo|gem squash|ginger|golden samphire|good king henry|grape leaves|green bean|green soybean|guar|habanero|haricot bean|horseradish|hubbard squash|hyacinth bean|iceberg lettuce|jerusalem artichoke|jicama|jute|kai-lan|kidney bean|kohlrabi|komatsuna|kombu|kuka|lacinto|lagos bologi|land cress|laver|leek|lemon grass|lentil|lettuce|lima bean|linguica|lo bok|lotus root|luffa|mache|malabar spinach|mangetout|mizuna greens|molokhia|monstera|morel|morogo|mung bean|mustard|napa cabbage|new zealand spinach|nopale|oceanic whitetip shark|okra|onion|oregano|orache|pak choy|paprika|parsley|parsnip|pea|peanut|pearl onion|pigeon pea|pignut|pimento|pinto bean|pisello|plantain|poblano|pokeweed|potato|prairie turnip|pumpkin|purslane|radicchio|radish|rape|rapini|raspberry|red bean|red cabbage|red pepper|rhubarb|ricebean|rocket|romanescu|romano bean|rosemary|runner bean|rutabaga|rye|saffron|sage|salad savoy|salsify|samphire|scallion|scarlet runner bean|sea kale|seakale beet|sesame|shallot|shiitake|skirret|sloe|snake bean|snow pea|sorrel|sour cherry|southern pea|soybean|spaghetti squash|spinach|spring onion|squash|squash blossom|swede|sweet corn|sweet pepper|sweet potato|swiss chard|taro|tatsoi|thyme|tomatillo|tomato|topinambour|tubers|turmeric|turnip|turnip greens|ugli fruit|ursolic acid|uva-ursi|vates|water chestnut|water spinach|watercress|wax bean|wax gourd|welsh onion|west indian gherkin|white bean|white radish|wild leek|wild rice|winged bean|winter melon|winter squash|yam bean|yardlong bean|yellow squash|yu choy|zucchini'\n",
    "meats = 'chicken|beef|pork|lamb|turkey|duck|goose|fish|seafood|salmon|shrimp|crab|lobster|ham|bacon|sausage|meat|steak|veal|venison|bison|liver|lamb|poultry|meat|tuna|mackerel|trout|haddock|cod|catfish|tilapia|sardine|anchovy|halibut|swordfish|monkfish|eel|octopus|squid|clams|mussels|oysters|snail|game|partridge|pheasant|quail|rabbit|hare|wild boar|elk|moose|reindeer|buffalo|ostrich|emu|kangaroo|alligator|frog legs|snapper|grouper|barracuda|carp|pike|perch|flounder|sole|mahi mahi|red snapper|swordfish|branzino|char|chub|mullet|ray|skate|sturgeon|turbot|whiting|arctic char|caviar|roe|scallop|sea urchin|abalone|crayfish|langoustine|prawn|cuttlefish|jellyfish|stingray|barramundi|black cod|bluefish|bonito|bream|burbot|butterfish|capelin|chimaera|conger|coral trout|dab|dace|dogfish|dorado|dory|drum|escolar|garfish|gilt-head bream|hake|herring|John Dory|kingfish|lamprey|lingcod|lumpsucker|marlin|milkfish|nile perch|northern pike|orange roughy|pacific saury|patagonian toothfish|pollock|pomfret|pompano|rockfish|rudd|sablefish|sanddab|sculpin|sea bass|shark|sheepshead|silver carp|skipjack tuna|smelt|snook|sockeye salmon|sole|sprat|striped bass|sturgeon|surimi|tarpon|tench|wahoo|walleye|warmouth|weakfish|whitebait|whitefish|yellowtail|zebrafish'\n",
    "dairy = 'milk|cheese|yogurt|cream|butter|buttermilk|sour cream|cottage cheese|mascarpone|ricotta|cream cheese|mozzarella|cheddar|brie|feta|parmesan|gouda|havarti|blue cheese|goat cheese|swiss cheese|provolone|muenster cheese|asiago|colby jack|mozzarella sticks|queso fresco|queso blanco|halloumi|neufchâtel|ghee|clotted cream'\n",
    "fruits = 'apple|banana|orange|grape|strawberry|blueberry|raspberry|blackberry|cherry|peach|pear|plum|pineapple|kiwi|lemon|lime|grapefruit|cantaloupe|watermelon|pomegranate|nectarine|apricot|fig|guava|lychee|mango|papaya|persimmon|star fruit|tangerine|dragon fruit|passion fruit|jackfruit|durian|breadfruit|quince|cranberry|currant|elderberry|gooseberry|boysenberry|lingonberry|mulberry|olive|date|prune|raisin|clementine|kumquat|tangelo|blood orange|carambola|loquat|ugli fruit|breadfruit|cherimoya|custard apple|guanabana|guava|horned melon|jujube|kiwano|kumquat|longan|lychee|mangosteen|marionberry|miracle fruit|papaya|persimmon|pomelo|quince|rambutan|sapodilla|tamarillo|tamarind|ugli fruit|yuzu|acai berry|ackee|araza|barbadine|bilberry|black sapote|blackcurrant|blueberry|boysenberry|breadfruit|canistel|cempedak|cherry|cloudberry|coconut|cranberry|cupuacu|currant|damson plum|durian|elderberry|feijoa|fig|goji berry|gooseberry|grape|grapefruit|guava|honeyberry|huckleberry|jabuticaba|jackfruit|jambul|jujube|juniper berry|kiwano|kiwi|kumquat|lemon|lime|lingonberry|loganberry|longan|loquat|lychee|mandarin orange|mango|marionberry|melon|mulberry|nectarine'\n",
    "alcohol = 'beer|wine|vodka|gin|rum|tequila|whiskey|brandy|bourbon|scotch|cognac|liqueur|vermouth|sherry|port|sake|champagne|prosecco|cider|mead|absinthe|amaretto|aperol|aquavit|armagnac|bitters|campari|chartreuse|cointreau|creme de cacao|creme de menthe|curacao|drambuie|frangelico|grand marnier|kahlua|lillet|limoncello|maraschino|midori|pastis|pisco|sambuca|schnapps|sloe gin|st. germain|triple sec|vermouth|absinthe|amaretto|aperol|aquavit|armagnac|bitters|campari|chartreuse|cointreau|creme de cacao|creme de menthe|curacao|drambuie|frangelico|grand marnier|kahlua|lillet|limoncello|maraschino|midori|pastis|pisco|sambuca|schnapps|sloe gin|st. germain|triple sec|vermouth'\n",
    "gluten_containing_grains = 'wheat|barley|rye|spelt|farro|kamut|triticale|bulgur|couscous|seitan|matzo|matzah|matzo meal|cake flour|pastry flour|bread flour|durum|semolina|einkorn|emmer|beer|ale|lager|porter|stout|malt|malt vinegar|soy sauce|teriyaki sauce|hoisin sauce|gravy|breadcrumbs|breaded|crouton|pretzel|pasta|noodle|gnocchi|dumpling|panko|sourdough|bagel|croissant|pita|naan|biscuit|scone|muffin|doughnut|pancake|waffle|pie crust|cake|pastry|cookie|brownie|cereal|granola|oats|oatmeal|oat bran|breakfast bars|communion wafer|play dough'\n",
    "nuts_seeds = 'almond|brazil nut|cashew|chestnut|filbert|hazelnut|macadamia nut|pecan|pine nut|pistachio|walnut|peanut|sunflower seed|pumpkin seed|sesame seed|flaxseed|chia seed|poppy seed|hemp seed|safflower seed|black seed|pomegranate seed|grape seed|apricot kernel|prune kernel|coconut|almond butter|cashew butter|peanut butter|sunflower seed butter|pumpkin seed butter|tahini (sesame seed butter)|nut butter|macadamia butter|pistachio butter|walnut butter|hazelnut butter|chestnut flour|almond flour|coconut flour|sunflower seed flour|flaxseed meal|chia flour|poppy seed oil|hemp seed oil|grape seed oil|walnut oil|almond oil|hazelnut oil|macadamia oil|pecan oil|pine nut oil|pistachio oil|acorn|beechnut|butternut|hickory nut|lychee nut|mongongo nut|pili nut|shea nut|soap nut|tiger nut|colocynth|guarana|jack nut|kola nut|malabar chestnut|ogbono nut|paradise nut|sapucaia nut|souari nut|tonka bean'\n",
    "\n",
    "#print('|'.join([f'{item}s?' for item in gluten_containing_grains.split('|')]))\n",
    "\n",
    "def extract_ingredients(row, string):\n",
    "\n",
    "    ingredients = row.split(',')\n",
    "    cleaned_ingredients = [ingredient.replace('\\\\', '').replace('\"', '').strip() for ingredient in ingredients]\n",
    "    cleaned_ingredients = [ingredient.replace('c(', '') for ingredient in cleaned_ingredients]\n",
    "    \n",
    "    plural_string = '|'.join([f'{item}s?' for item in string.split('|')])\n",
    "\n",
    "    count = 0\n",
    "    for ingredient in cleaned_ingredients: \n",
    "        if bool(re.search(plural_string, ingredient, re.IGNORECASE)):\n",
    "            #print(ingredient)\n",
    "            #print(plural_string[0])\n",
    "            #print(ingredient)\n",
    "            count += 1\n",
    "\n",
    "    #print(cleaned_ingredients)\n",
    "    #print(vegetables_count)\n",
    "    \n",
    "    return count\n",
    "\n",
    "recipes_cleaned['VegetableCount'] = recipes_cleaned['RecipeIngredientParts'].apply(lambda row: extract_ingredients(row, vegetables))\n",
    "recipes_cleaned['MeatCount'] = recipes_cleaned['RecipeIngredientParts'].apply(lambda row: extract_ingredients(row, meats))\n",
    "recipes_cleaned['DairyCount'] = recipes_cleaned['RecipeIngredientParts'].apply(lambda row: extract_ingredients(row, dairy))\n",
    "recipes_cleaned['FruitsCount'] = recipes_cleaned['RecipeIngredientParts'].apply(lambda row: extract_ingredients(row, fruits))\n",
    "recipes_cleaned['AlcoholCount'] = recipes_cleaned['RecipeIngredientParts'].apply(lambda row: extract_ingredients(row, alcohol))\n",
    "recipes_cleaned['GlutenContainingGrainsCount'] = recipes_cleaned['RecipeIngredientParts'].apply(lambda row: extract_ingredients(row, gluten_containing_grains))\n",
    "recipes_cleaned['NutsAndSeedsCount'] = recipes_cleaned['RecipeIngredientParts'].apply(lambda row: extract_ingredients(row, nuts_seeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Name' column\n",
    "recipes_cleaned.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "# Handling the Time columns \n",
    "recipes_cleaned[\"TotalTimeRequired\"] = recipes_cleaned[\"CookTime\"] + recipes_cleaned[\"PrepTime\"]\n",
    "recipes_cleaned.drop([\"CookTime\", \"PrepTime\"], axis=1, inplace=True)\n",
    "\n",
    "# Handling the RecipeCategory column\n",
    "recipes_cleaned = pd.get_dummies(recipes_cleaned, columns=['RecipeCategory'], drop_first=True)\n",
    "\n",
    "# Handling the RecipeIngredientQuantities column\n",
    "recipes_cleaned.drop(columns=['RecipeIngredientQuantities'], inplace=True)\n",
    "\n",
    "# Handling the RecipeIngredientParts column\n",
    "recipes_cleaned.drop(columns=['RecipeIngredientParts'], inplace=True)\n",
    "\n",
    "# Handling the Calories column\n",
    "recipes_cleaned.loc[recipes_cleaned[\"Calories\"] > 30000, \"Calories\"] = recipes_cleaned[\"Calories\"].median()\n",
    "\n",
    "# Handling the CholesterolContent column\n",
    "recipes_cleaned.drop(columns=['CholesterolContent'], inplace=True)\n",
    "\n",
    "# Handling the SodiumContent column\n",
    "recipes_cleaned.drop(columns=['SodiumContent'], inplace=True)\n",
    "\n",
    "# Handling the RecipeServings column\n",
    "recipes_cleaned.drop(columns=['RecipeServings'], inplace=True)\n",
    "\n",
    "# Handling the RecipeYield column\n",
    "recipes_cleaned.drop(columns=['RecipeYield'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FatContent, SaturatedFatContent, CarbohydrateContent, FiberContent, SugarContent, ProteinContent\n",
    "\n",
    "# FatContent\n",
    "recipes_cleaned.loc[recipes_cleaned[\"FatContent\"] > 100, \"FatContent\"] = recipes_cleaned[\"FatContent\"].median()\n",
    "\n",
    "# SaturatedFatContent\n",
    "recipes_cleaned.loc[recipes_cleaned[\"SaturatedFatContent\"] > 100, \"SaturatedFatContent\"] = recipes_cleaned[\"SaturatedFatContent\"].median()\n",
    "\n",
    "# CarbohydrateContent\n",
    "recipes_cleaned.loc[recipes_cleaned[\"CarbohydrateContent\"] > 100, \"CarbohydrateContent\"] = recipes_cleaned[\"CarbohydrateContent\"].median()\n",
    "\n",
    "# FiberContent\n",
    "recipes_cleaned.loc[recipes_cleaned[\"FiberContent\"] > 100, \"FiberContent\"] = recipes_cleaned[\"FiberContent\"].median()\n",
    "\n",
    "# SugarContent\n",
    "recipes_cleaned.loc[recipes_cleaned[\"SugarContent\"] > 100, \"SugarContent\"] = recipes_cleaned[\"SugarContent\"].median()\n",
    "\n",
    "# ProteinContent\n",
    "recipes_cleaned.loc[recipes_cleaned[\"ProteinContent\"] > 100, \"ProteinContent\"] = recipes_cleaned[\"ProteinContent\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Requests ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_df.head()\n",
    "requests_cleaned = requests_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling the Time Column \n",
    "# Replace negative values in the Time Column with a very high number\n",
    "requests_cleaned.loc[requests_cleaned[\"Time\"] < 0, \"Time\"] = 1000000000000000000\n",
    "\n",
    "# Handling the HighCalories column \n",
    "requests_cleaned['HighCalories'] = requests_df['HighCalories'].astype('int')\n",
    "\n",
    "# Handling the HighProtein column\n",
    "requests_cleaned['HighProtein'] = requests_df['HighProtein'].map({'Yes': 1, 'Indifferent': 0})\n",
    "\n",
    "# Handling the LowFat column\n",
    "\n",
    "# Handling the LowSugar column\n",
    "requests_cleaned['LowSugar'] = requests_df['LowSugar'].map({'0': 1, 'Indifferent': 0})\n",
    "\n",
    "requests_cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Reviews ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.head()\n",
    "reviews_cleaned = reviews_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling the Rating Column \n",
    "# Replace the missing values with 0\n",
    "reviews_cleaned['Rating'].fillna(0, inplace=True)\n",
    "\n",
    "#reviews_cleaned.drop(columns=['Rating'], inplace=True)\n",
    "\n",
    "# Handling the Like Column \n",
    "reviews_cleaned['Like'] = reviews_cleaned['Like'].map({True: 1, False: 0})\n",
    "\n",
    "\n",
    "# Handling the TestSetId Column\n",
    "reviews_cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Diet Shape: \", diet_cleaned.shape)\n",
    "print(\"Recipes Shape: \", recipes_cleaned.shape)\n",
    "print(\"Requests Shape: \", requests_cleaned.shape)\n",
    "print(\"Reviews Shape: \", reviews_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(requests_cleaned, reviews_cleaned, on=['RecipeId', 'AuthorId'])\n",
    "full_df = pd.merge(full_df, recipes_cleaned, on=['RecipeId'])\n",
    "full_df = pd.merge(full_df, diet_cleaned, on=['AuthorId'])\n",
    "\n",
    "print(full_df.shape)\n",
    "\n",
    "full_df.loc[full_df[\"RecipeId\"] == 133043]\n",
    "\n",
    "full_df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full DF Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Data Engineernig \n",
    "\n",
    "# TimeRequestFulfilled -> 1, if TotalTime is less Time\n",
    "full_df = full_df.assign(TimeRequestFulfilled = np.where(full_df['TotalTimeRequired'] <= full_df['Time'], 1, 0))\n",
    "\n",
    "# VegetarianRequestFulfilled -> 1, if Diet_Vegetarian is 1 and ProteinContent is in the 0.5 quantile\n",
    "#full_df = full_df.assign(VegetarianRequestFulfilled = np.where((full_df['Diet_Vegetarian'] == 1) & (full_df['MeatCount'] == 0), 1, 0))\n",
    "\n",
    "# VeganRequestFulfilled -> 1, if Diet_Vegan is 1 and ProteinContent is in the 0.5 quantile\n",
    "#full_df = full_df.assign(VeganRequestFulfilled = np.where((full_df['Diet_Vegan'] == 1) & (full_df['MeatCount'] == 0) & (full_df['DairyCount'] == 0), 1, 0))\n",
    "\n",
    "# High Calories -> 1, if HighCalories is 1 and if CaloriesContent is more than 500 \n",
    "full_df = full_df.assign(HighCaloriesRequestFulfilled = np.where((full_df[\"HighCalories\"] == 1) & (full_df['Calories'] >= 300), 1, 0))\n",
    "\n",
    "# LowFatRequestFulfilled -> 1, if LowFat is 1, and FatContent is less than 3\n",
    "full_df = full_df.assign(LowFatRequestFulfilled = np.where((full_df['LowFat'] == 1) & (full_df['FatContent'] < 13), 1, 0))\n",
    "\n",
    "# HighProteinRequestFulfilled -> 1, if ProteinContent is more than 25 \n",
    "full_df = full_df.assign(HighProteinRequestFulfilled = np.where((full_df[\"HighProtein\"] == 1) & (full_df['ProteinContent'] >= 25), 1, 0))\n",
    "\n",
    "# LowSugarRequestFulfilled -> 1, if LowSugar is 1, and SugarContent is less than 5\n",
    "full_df = full_df.assign(LowSugarRequestFulfilled = np.where((full_df['LowSugar'] == 1) & (full_df['SugarContent'] < 6), 1, 0))\n",
    "\n",
    "# HighFiberRequestFulfilled -> 1, if FiberContent is more than 10\n",
    "full_df = full_df.assign(HighFiberRequestFulfilled = np.where((full_df['FiberContent'] == 1) & (full_df['FiberContent'] >= 4.5), 1, 0))\n",
    "\n",
    "# VegeterianRequestFulfilled -> 1, if Diet_Vegetarian is 1 and MeatCount is 0\n",
    "full_df = full_df.assign(VegeterianRequestNotFulfilled = np.where((full_df['Diet_Vegetarian'] == 1) & (full_df['MeatCount'] != 0), 1, 0))\n",
    "\n",
    "# VeganRequestFulfilled -> 1, if Diet_Vegan is 1 and MeatCount is 0 and DairyCount is 0\n",
    "full_df = full_df.assign(VeganRequestNotFulfilled = np.where((full_df['Diet_Vegan'] == 1) & ((full_df['MeatCount'] != 0) | (full_df['DairyCount'] != 0)), 1, 0))\n",
    "\n",
    "# OmnivoreRequestFulfilled -> 1, if Diet_Vegan is 0 and Diet_Vegetarian is 0 and MeatCount is not 0\n",
    "full_df = full_df.assign(OmnivoreRequestFulfilled = np.where((full_df['Diet_Vegan'] == 0) & (full_df['Diet_Vegetarian'] == 0) & (full_df['MeatCount'] != 0), 1, 0))\n",
    "\n",
    "full_df[\"VeganRequestNotFulfilled\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_submission = full_df[full_df[\"Like\"].isnull()]\n",
    "full_df_modelling = full_df[full_df[\"Like\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "\n",
    "X = full_df_modelling.drop([\"AuthorId\", \"RecipeId\", \"Like\", \"TestSetId\", \"Time\", \"TimeRequestFulfilled\"], axis=1)\n",
    "y = full_df_modelling[\"Like\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(X, y,\n",
    "                   test_size=0.3, \n",
    "                   shuffle=True,\n",
    "                   random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Create the model\n",
    "dt = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# Fit the model\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "predictions = dt.predict(X_test)\n",
    "\n",
    "# Calculate the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run the GradientBooster4000\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Create the model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=4000)\n",
    "\n",
    "# Fit the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Calculate the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Evaluate model\n",
    "print(\"confusion matrix\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"classification report\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Plotting using seaborn for better visualization\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Doesn't change\n",
    "submission_predictions = gb_model.predict(full_df_submission.drop([\"AuthorId\", \"RecipeId\", \"Like\", \"TestSetId\", \"Time\", \"TimeRequestFulfilled\"], axis=1))\n",
    "\n",
    "\n",
    "output = pd.DataFrame({'id': full_df_submission.TestSetId.astype(int), 'prediction': submission_predictions.astype(int)})\n",
    "output = output.sort_values('id')\n",
    "output.to_csv('../predictions_analytics_acrobats_3.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
